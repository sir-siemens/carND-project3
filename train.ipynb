{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### First read data from the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "%matplotlib inline\n",
    "\n",
    "def load_training_data(directory):\n",
    "    df_raw = pd.read_csv('./'+directory+'/driving_log.csv')\n",
    "    df_raw.columns = ['center','left','right','steering','throttle','brake','speed']\n",
    "    directory_series = np.empty( len(df_raw), dtype=object)\n",
    "    directory_series[:] = directory\n",
    "    df_raw['directory'] = pd.Series( directory_series, index=df_raw.index)\n",
    "    return df_raw\n",
    "\n",
    "def plot_hist(dataframe, bins = 20):  \n",
    "    steering_cmds = dataframe.as_matrix(columns=['steering'])\n",
    "    steering_data = steering_cmds[:,0]\n",
    "    n, bins, patches = plt.hist(steering_data, bins, facecolor='green', alpha=0.75)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "directory1 = 'training_data1'\n",
    "df_straight = load_training_data(directory1)\n",
    "directory2 = 'training_data_turn'\n",
    "df_turn = load_training_data(directory2)\n",
    "directory3 = 'training_data_turn2'\n",
    "df_turn2 = load_training_data(directory2)\n",
    "\n",
    "# preprocessing throw all the data where speed is smaller than 2\n",
    "print (len(df_straight))\n",
    "print (len(df_turn))\n",
    "print (len(df_turn2))\n",
    "\n",
    "df_turn_preprocess = df_turn[ df_turn.speed > 5 ] \n",
    "df_straight_preprocess = df_straight[ ((df_straight.speed > 20.0) & (df_straight.speed < 30.0))] \n",
    "df_turn2_preprocess = df_turn2[ df_turn2.speed > 5 ] \n",
    "\n",
    "#df[ ((df.steering > -0.3) & (df.steering < -0.25) )]\n",
    "\n",
    "frames = [df_turn_preprocess, df_straight_preprocess, df_turn2_preprocess]\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "print (len(df_straight_preprocess))\n",
    "print (len(df_turn_preprocess))\n",
    "print (len(df_turn2_preprocess))\n",
    "print (len(df))\n",
    "plt.figure(figsize=(5,10))\n",
    "plt.subplot(4, 1, 1)\n",
    "plot_hist(df_straight_preprocess)\n",
    "plt.subplot(4, 1, 2)\n",
    "plot_hist(df_turn_preprocess)\n",
    "plt.subplot(4, 1, 3)\n",
    "plot_hist(df_turn2_preprocess)\n",
    "plt.subplot(4, 1, 4)\n",
    "plot_hist(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# spllit train validation \n",
    "# split df_merge into training and validation set\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train_samples = df[msk]\n",
    "validation_samples = df[~msk]\n",
    "print ('training n %d', len(train_samples))\n",
    "print ('validation n %d', len(validation_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df_merge = df\n",
    "for i in range(len(bins)-1):\n",
    "    df_sub = df.loc[lambda df: (df.steering >= bins[i]) , :].copy()\n",
    "    df_sub_ =  df_sub.loc[lambda df: (df.steering < bins[i+1]) , :].copy()\n",
    "    data_frames = [df_merge, df_sub_]   \n",
    "    duplicate = 2000/n[i]\n",
    "    # print duplicate\n",
    "    for j in range( int(duplicate) ):\n",
    "        df_merge = pd.concat(data_frames, ignore_index=True)\n",
    "        data_frames = [df_merge, df_sub_]\n",
    "steering_cmds = df_merge.as_matrix(columns=['steering'])\n",
    "steering_data = steering_cmds[:,0]\n",
    "\n",
    "#plt.subplot(3, 1, 2)\n",
    "#n, bins, patches = plt.hist(steering_data, 10, facecolor='blue', alpha=0.75)    \n",
    "\n",
    "# split df_merge into training and validation set\n",
    "msk = np.random.rand(len(df_merge)) < 0.8\n",
    "train_samples = df_merge[msk]\n",
    "validation_samples = df_merge[~msk]\n",
    "print ('training n %d', len(train_samples))\n",
    "print ('validation n %d', len(validation_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#df.steering < 0.4 &  > -0.4\n",
    "df_inspect = df[ ((df.steering > -0.3) & (df.steering < -0.25) )]\n",
    "#df.loc[lambda df: df.steering < 0.4 and df.steering > -0.4 , :]\n",
    "print (len(df_inspect))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (5,5*58))\n",
    "index = 0\n",
    "for row_index, series in df_inspect.iterrows():\n",
    "    name = './'+directory+'/IMG/'+series.center.split('/')[-1]\n",
    "    image = cv2.imread(name)\n",
    "    index+=1\n",
    "    plt.subplot(len(df_inspect), 1, index)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "samples = train_samples\n",
    "num_samples = len(samples)\n",
    "batch_size = 32\n",
    "print (num_samples)\n",
    "df_batch_samples = samples[0:64]\n",
    "df_batch_samples.reset_index(drop=True)\n",
    "df_batch_samples\n",
    "for row_index, series in df_batch_samples.iterrows():\n",
    "    pass\n",
    "\n",
    "#for offset in range(0, num_samples, batch_size):\n",
    "#    pass\n",
    "#for offset in range(0, num_samples, batch_size):\n",
    "#    df_batch_samples = samples[offset:offset+batch_size]\n",
    "#    for row_index, series in df_batch_samples:\n",
    "#                name = './IMG/'+series.center.split('/')[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def offset(steering_angle):\n",
    "    max_offset = 0.3\n",
    "    min_offset = 0.1\n",
    "    param_a = (max_offset -  min_offset) / (0.4*0.4)\n",
    "    offset = param_a * steering_angle * steering_angle + min_offset\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        # shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            df_batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for row_index, series in df_batch_samples.iterrows():\n",
    "                name = './'+ series.directory+'/IMG/'+series.center.split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(series.steering)\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "            \n",
    "                left_name = './'+ series.directory+'/IMG/'+series.left.split('/')[-1]\n",
    "                left_image = cv2.imread(left_name)\n",
    "                left_angle = float(series.steering) + offset(float(series.steering))\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "                \n",
    "                right_name = './'+ series.directory+'/IMG/'+series.right.split('/')[-1]\n",
    "                right_image = cv2.imread(right_name)\n",
    "                right_angle = float(series.steering) - offset(float(series.steering))\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                \n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "           \n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "            #return sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "\n",
    "            \n",
    "# compile and train the model using the generator function\n",
    "\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "(X_training, y_train) =  next(train_generator)\n",
    "\n",
    "random_image = random.randint(0 , X_training.shape[0])   \n",
    "#plt.figure( figsize =(100,100))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow( cv2.cvtColor(X_training[random_image], cv2.COLOR_BGR2RGB) )\n",
    "#plt.subplot(3, 1, 2)\n",
    "#plt.imshow( cv2.cvtColor(X_training_left[random_image], cv2.COLOR_BGR2RGB) )\n",
    "#plt.subplot(3, 1, 3)\n",
    "#plt.imshow( cv2.cvtColor(X_training_right[random_image], cv2.COLOR_BGR2RGB) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## use left and right image to train on non zero datas \n",
    "df.loc[lambda df: df.steering != 0, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X_training_flip = np.zeros([y_train_initial_aug.shape[0], 160 , 320 , 3 ], dtype=np.uint8)\n",
    "for i in range(y_train_initial_aug.shape[0]):\n",
    "    X_training_flip[i] =  np.fliplr(X_train_initial_aug[i])\n",
    "y_train_flip = -y_train_initial_aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# stack training data\n",
    "X_training =  np.vstack( (X_train_initial_aug,X_training_flip) )\n",
    "y_train =  np.concatenate( (y_train_initial_aug, y_train_flip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense , Lambda, MaxPooling2D, Dropout,Cropping2D\n",
    "\n",
    "i_shape = (160, 320,3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=i_shape ))\n",
    "model.add(Cropping2D(cropping=((60,25), (0,0)), input_shape=(160,320,3)))\n",
    "\n",
    "# conv_net\n",
    "model.add(Conv2D( 6, 5, 5, activation='relu' ))\n",
    "model.add(Conv2D( 6, 5, 5,  activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "########################################################################\n",
    "# conv_net\n",
    "model.add(Conv2D(16, 3, 3, activation='relu'))\n",
    "model.add(Conv2D(16, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#########################################################################\n",
    "model.add(Flatten())\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "#model.fit(X_training, y_train, validation_split = 0.2, shuffle=True)\n",
    "model.fit_generator(train_generator, samples_per_epoch= 3*len(train_samples), validation_data=validation_generator, nb_val_samples=3*len(validation_samples), nb_epoch=5)\n",
    "model.save('first_model.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model_fine_tune.h5')\n",
    "model.fit_generator(train_generator, samples_per_epoch= 3*len(train_samples), validation_data=validation_generator, nb_val_samples=3*len(validation_samples), nb_epoch=5)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
