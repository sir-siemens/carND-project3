{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### First read data from the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "%matplotlib inline\n",
    "\n",
    "def load_training_data(directory):\n",
    "    df_raw = pd.read_csv('./'+directory+'/driving_log.csv')\n",
    "    df_raw.columns = ['center','left','right','steering','throttle','brake','speed']\n",
    "    directory_series = np.empty( len(df_raw), dtype=object)\n",
    "    directory_series[:] = directory\n",
    "    df_raw['directory'] = pd.Series( directory_series, index=df_raw.index)\n",
    "    return df_raw\n",
    "\n",
    "def plot_hist(dataframe, bins = 20):  \n",
    "    steering_cmds = dataframe.as_matrix(columns=['steering'])\n",
    "    steering_data = steering_cmds[:,0]\n",
    "    n, bins, patches = plt.hist(steering_data, bins, facecolor='green', alpha=0.75)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "directory1 = 'training_data1'\n",
    "df_straight = load_training_data(directory1)\n",
    "directory2 = 'training_data_turn'\n",
    "df_turn = load_training_data(directory2)\n",
    "directory3 = 'training_data_turn2'\n",
    "df_turn2 = load_training_data(directory3)\n",
    "directory4 = 'training_data_3'\n",
    "df_train4 = load_training_data(directory4)\n",
    "\n",
    "\n",
    "# preprocessing throw all the data where speed is smaller than 2\n",
    "\n",
    "df_turn_preprocess = df_turn[ df_turn.speed > 5 ] \n",
    "df_straight_preprocess = df_straight[ ((df_straight.speed > 20.0) & (df_straight.speed < 30.0))] \n",
    "df_turn2_preprocess = df_turn2[ df_turn2.speed > 5 ] \n",
    "df_train4_preprocess =  df_train4[ df_train4.speed > 3] \n",
    "\n",
    "#df[ ((df.steering > -0.3) & (df.steering < -0.25) )]\n",
    "\n",
    "frames = [df_turn_preprocess, df_straight_preprocess, df_turn2_preprocess, df_train4_preprocess]\n",
    "df = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "print (len(df_straight_preprocess))\n",
    "print (len(df_turn_preprocess))\n",
    "print (len(df_turn2_preprocess))\n",
    "print (len(df_train4_preprocess))\n",
    "\n",
    "print (len(df))\n",
    "plt.figure(figsize=(5,10))\n",
    "plt.subplot(5, 1, 1)\n",
    "plot_hist(df_straight_preprocess)\n",
    "plt.subplot(5, 1, 2)\n",
    "plot_hist(df_turn_preprocess)\n",
    "plt.subplot(5, 1, 3)\n",
    "plot_hist(df_turn2_preprocess)\n",
    "plt.subplot(5, 1, 4)\n",
    "plot_hist(df_train4_preprocess)\n",
    "plt.subplot(5, 1, 5)\n",
    "plot_hist(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# spllit train validation \n",
    "# split df_merge into training and validation set\n",
    "msk = np.random.rand(len(df)) < 0.8\n",
    "train_samples = df[msk]\n",
    "validation_samples = df[~msk]\n",
    "print ('training n %d', len(train_samples))\n",
    "print ('validation n %d', len(validation_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_offset(steering_angle):\n",
    "    max_offset = 0.3\n",
    "    min_offset = 0.1\n",
    "    param_a = (max_offset -  min_offset) / (0.4*0.4)\n",
    "    offset = param_a * steering_angle * steering_angle + min_offset\n",
    "    return offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1: # Loop forever so the generator never terminates\n",
    "        #shuffle(samples)\n",
    "        samples.apply(np.random.permutation)\n",
    "        #print (samples.speed[0:3])\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            df_batch_samples = samples[offset:offset+batch_size]\n",
    "            \n",
    "            images = []\n",
    "            angles = []\n",
    "            for row_index, series in df_batch_samples.iterrows():\n",
    "                name = './'+ series.directory+'/IMG/'+series.center.split('/')[-1]\n",
    "                center_image = cv2.imread(name)\n",
    "                center_angle = float(series.steering)\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "                \n",
    "                # flip image \n",
    "                center_image_flipped = np.fliplr(center_image)\n",
    "                center_image_flipped_cmd = -center_angle\n",
    "                images.append(center_image_flipped)\n",
    "                angles.append(center_image_flipped_cmd)                \n",
    "            \n",
    "                left_name = './'+ series.directory+'/IMG/'+series.left.split('/')[-1]\n",
    "                left_image = cv2.imread(left_name)\n",
    "                left_angle = float(series.steering) + compute_offset(float(series.steering))\n",
    "                images.append(left_image)\n",
    "                angles.append(left_angle)\n",
    "\n",
    "                # flip left image \n",
    "                left_image_flipped = np.fliplr(left_image)\n",
    "                left_image_flipped_cmd = -left_angle\n",
    "                images.append(left_image_flipped)\n",
    "                angles.append(left_image_flipped_cmd)                \n",
    "\n",
    "            \n",
    "                right_name = './'+ series.directory+'/IMG/'+series.right.split('/')[-1]\n",
    "                right_image = cv2.imread(right_name)\n",
    "                right_angle = float(series.steering) - compute_offset(float(series.steering))\n",
    "                images.append(right_image)\n",
    "                angles.append(right_angle)\n",
    "                \n",
    "                right_image_flipped = np.fliplr(right_image)\n",
    "                right_image_flipped_cmd = -right_angle\n",
    "                images.append(right_image_flipped)\n",
    "                angles.append(right_image_flipped_cmd)\n",
    "           \n",
    "            \n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "           \n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "            #return sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "\n",
    "            \n",
    "# compile and train the model using the generator function\n",
    "\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Visualize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "(X_training, y_train) =  next(train_generator)\n",
    "\n",
    "random_image = random.randint(0 , X_training.shape[0])   \n",
    "#plt.figure( figsize =(100,100))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow( cv2.cvtColor(X_training[random_image], cv2.COLOR_BGR2RGB) )\n",
    "#plt.subplot(3, 1, 2)\n",
    "#plt.imshow( cv2.cvtColor(X_training_left[random_image], cv2.COLOR_BGR2RGB) )\n",
    "#plt.subplot(3, 1, 3)\n",
    "#plt.imshow( cv2.cvtColor(X_training_right[random_image], cv2.COLOR_BGR2RGB) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## use left and right image to train on non zero datas \n",
    "df.loc[lambda df: df.steering != 0, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense , Lambda, MaxPooling2D, Dropout,Cropping2D\n",
    "\n",
    "i_shape = (160, 320,3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 127.5 - 1.0, input_shape=i_shape ))\n",
    "model.add(Cropping2D(cropping=((60,25), (0,0)), input_shape=(160,320,3)))\n",
    "\n",
    "# conv_net\n",
    "model.add(Conv2D( 6, 5, 5, activation='relu' ))\n",
    "model.add(Conv2D( 6, 5, 5,  activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "########################################################################\n",
    "# conv_net\n",
    "model.add(Conv2D(16, 3, 3, activation='relu'))\n",
    "model.add(Conv2D(16, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#########################################################################\n",
    "model.add(Flatten())\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(84, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "#model.fit(X_training, y_train, validation_split = 0.2, shuffle=True)\n",
    "model.fit_generator(train_generator, samples_per_epoch= 3*len(train_samples), validation_data=validation_generator, nb_val_samples=3*len(validation_samples), nb_epoch=5)\n",
    "model.save('first_model.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense , Lambda, MaxPooling2D, Dropout,Cropping2D\n",
    "\n",
    "i_shape = (160, 320,3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: x / 255.0 - 0.5, input_shape=i_shape ))\n",
    "model.add(Cropping2D(cropping=((60,25), (0,0)), input_shape=(160,320,3)))\n",
    "\n",
    "# conv_net\n",
    "model.add(Conv2D( 24, 5, 5, activation='relu' ))\n",
    "model.add(Conv2D( 36, 5, 5,  activation='relu'))\n",
    "model.add(Conv2D( 48, 5, 5,  activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "########################################################################\n",
    "# conv_net\n",
    "model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "model.add(Conv2D(64, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#########################################################################\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse',optimizer='adam')\n",
    "#model.fit(X_training, y_train, validation_split = 0.2, shuffle=True)\n",
    "model.fit_generator(train_generator, samples_per_epoch= 6 * len(train_samples), validation_data=validation_generator, nb_val_samples=6 * len(validation_samples), nb_epoch=5)\n",
    "model.save('nvidia_model.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tune "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('first_model.h5')\n",
    "model.fit_generator(train_generator, samples_per_epoch= 3*len(train_samples), validation_data=validation_generator, nb_val_samples=3*len(validation_samples), nb_epoch=5)\n",
    "model.save('first_model_fine_tune.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
